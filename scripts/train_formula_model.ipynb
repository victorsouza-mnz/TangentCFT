{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration \n",
    "\n",
    "- This first step is the configuration step, set variables that are going to control how the training is going to proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINING_DATA_PATH = \"\"\n",
    "TRAINING_DATA_ORIGIN = \"wiki\"\n",
    "CONFIGURATION_FILE_PATH = \"Configuration/config/config_1\"\n",
    "DATA_STRUCTURE_TYPE = \"slt\"\n",
    "SLT_ENCODER_MAP_PATH = \"\"\n",
    "OPT_ENCODER_MAP_PATH = \"\"\n",
    "\n",
    "\n",
    "MODEL_FILE_PATH = \"lib/trained_model/slt_model\"\n",
    "\n",
    "# Embedding parameters\n",
    "TOKENIZE_ALL = False\n",
    "TOKENIZE_NUMBERS = True\n",
    "IGNORE_FULL_RELATIVE_PATH = True\n",
    "EMBEDDING_TYPE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ THE DATA IN TUPLES OF SLT OR OPT\n",
    "from DataReader.wiki_data_reader import WikiDataReader\n",
    "from DataReader.mse_data_reader import MSEDataReader\n",
    "\n",
    "print(\"Reading data to train the model...\")\n",
    "print(f\"Data structure type: {DATA_STRUCTURE_TYPE}\")\n",
    "\n",
    "if TRAINING_DATA_ORIGIN == \"wiki\":\n",
    "    data_reader = WikiDataReader(TRAINING_DATA_PATH, DATA_STRUCTURE_TYPE == 'slt')\n",
    "else:\n",
    "    data_reader = MSEDataReader(TRAINING_DATA_PATH, DATA_STRUCTURE_TYPE == 'slt')\n",
    "\n",
    "\n",
    "dictionary_formula_slt_tuple = data_reader.get_collection()\n",
    "\n",
    "print(f\"Data readed in slt format!, Number of formulas in the training data: {len(dictionary_formula_slt_tuple.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODE ALL THE TUPLES AND SAVE IN THE ENCODER MAP\n",
    "print(\"Encoding all the tuples and saving in the encoder map...\")\n",
    "\n",
    "from lib.tangentCFT.touple_encoder.encoder import (EncoderManager)\n",
    "\n",
    "count = 0\n",
    "dictionary_slt_encoded_tuples = {}\n",
    "\n",
    "encoder_manager = EncoderManager()\n",
    "\n",
    "for formula in dictionary_formula_slt_tuple:\n",
    "    count += 1\n",
    "    if count % 1000 == 0:\n",
    "        print(f\"Encoded {count} formulas\")\n",
    "\n",
    "    dictionary_slt_encoded_tuples[formula] = encoder_manager.encode_tuples(\n",
    "        dictionary_formula_slt_tuple[formula],\n",
    "        EMBEDDING_TYPE,\n",
    "        IGNORE_FULL_RELATIVE_PATH,\n",
    "        TOKENIZE_ALL,\n",
    "        TOKENIZE_NUMBERS,\n",
    "    )\n",
    "\n",
    "print(f\"All {count} formulas encoded and saved in the encoder map!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN AND SAVE THE MODEL\n",
    "from services.tanget_cft_service import TangentCFTService\n",
    "from Configuration.configuration import Configuration\n",
    "\n",
    "\n",
    "print(\"loading the fast text training configuration...\")\n",
    "config = Configuration(CONFIGURATION_FILE_PATH)\n",
    "\n",
    "print(\"training the fast text model...\")\n",
    "tangent_cft_service = TangentCFTService()\n",
    "\n",
    "\n",
    "tangent_cft_service.train_model(\n",
    "  config, list(dictionary_slt_encoded_tuples.values())\n",
    ")\n",
    "\n",
    "print(f\"saving the fast text model in {MODEL_FILE_PATH}...\")\n",
    "tangent_cft_service.save_model(MODEL_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
